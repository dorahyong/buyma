Gemini
엔터프라이즈 로고
AI로 같은 패딩 사진 판별하기
https://gemini.google.com/share/047b8ba95e57
사용 모드: Pro 2026년 1월 15일 오후 05:39
게시 날짜: 2026년 1월 15일 오후 05:56
각기 다른 이미지인데, 똑같은 패딩을 입고있는 사진이 있다고 가정해볼게. 하나는 대단히 비슷한 분위기이지만 혹은 같은 인물이지만 비슷한 패딩을 입고 있는 이미지가 있다고 가정해볼게.

그러면 사람같은 경우에는 이걸 쉽게, 옷의 디테일을 비교를 해본다던가 해서, A이미지와 B이미지가 같은 패딩제품의 사진이다 라고 쉽게 판별을 할수가 있잖아? 근데 프로그램으로는 이런게 불가능하단말이지. 아얘 같은 이미지가 포함되어있냐 여부정도야 비교를 할 수도 있겠지만. 하지만 프로그램이 못하고 사람만 할 수 있는걸 대체해줄 수 있는게 AI잖아? AI로 이런 작업이 가능할것 같아? 가능하다면 어떤 방법론으로 접근해야할것같아?

네, 정확히 보셨습니다. AI는 말씀하신 '사람이 옷의 디테일을 보고 판단하는 과정'을 모방하고, 때로는 더 정교하게 수행할 수 있습니다.

단순히 "비슷한 이미지인가?"를 넘어 **"다른 환경에서 찍혔지만, 논리적으로 같은 제품인가?"**를 판별하는 것은 컴퓨터 비전 분야에서 'Re-Identification (재식별)' 또는 **'Fine-Grained Visual Categorization (세밀한 시각적 분류)'**라고 불리는 고난도 작업입니다.

이 문제를 해결하기 위한 기술적 접근 방법론을 단계별로 정리해 드립니다.

1. 핵심 방법론: 딥 메트릭 러닝 (Deep Metric Learning)
가장 핵심이 되는 접근법입니다. AI에게 "이것은 패딩이다"라고 가르치는 분류(Classification) 방식이 아니라, **"이 두 사진의 거리는 가깝고(같은 제품), 저 두 사진의 거리는 멀다(다른 제품)"**라는 거리 개념을 학습시키는 것입니다.

샴 네트워크 (Siamese Networks): 두 개의 이미지를 동시에 신경망에 통과시켜서 나온 특징값(Feature Vector)을 비교합니다.

트리플렛 손실 (Triplet Loss): 학습 시 3장의 사진을 한 세트로 묶습니다.

기준 사진 (Anchor)

같은 제품의 다른 사진 (Positive)

매우 비슷하게 생겼지만 다른 제품 사진 (Negative)

목표: Anchor와 Positive의 거리는 좁히고, Anchor와 Negative의 거리는 멀어지도록 학습합니다. 이렇게 하면 '비슷해 보이는 가짜'를 걸러내는 능력이 생깁니다.

2. 세부 디테일 포착: 어텐션 메커니즘 (Attention Mechanism)
사람이 패딩을 구별할 때 전체적인 색상뿐만 아니라 로고의 위치, 지퍼의 모양, 박음질 패턴 등을 보는 것과 같은 원리입니다.

공간적 어텐션 (Spatial Attention): 이미지 전체에서 배경이나 사람의 얼굴은 무시하고, 옷의 중요한 특징(로고, 주머니, 재질감 등)이 있는 영역에 가중치를 둡니다.

부분 특징 추출 (Part-based Feature Extraction): 옷을 전체 통으로 보지 않고 소매, 몸통, 깃 등으로 나누어 각각의 특징을 추출한 뒤 종합하여 판단합니다. 이렇게 하면 사람이 포즈를 취해서 옷이 구겨지거나 접혀 있어도 구별이 가능해집니다.

3. 전처리 단계: 객체 검출 및 분할 (Detection & Segmentation)
이미지 전체를 비교하면 배경(카페, 야외 등) 때문에 다른 제품으로 인식할 오류가 큽니다.

배경 제거: YOLO나 Mask R-CNN 같은 모델을 사용하여 사진에서 정확히 '패딩' 영역만 오려냅니다(Cropping).

포즈 정렬 (Pose Alignment): 사람이 옆으로 서 있거나 팔을 들고 있을 때, 옷의 이미지를 펴진 상태로 보정하거나, 랜드마크(어깨, 허리 등)를 기준으로 특징을 매칭합니다.

4. 실제 작동 프로세스 예시
만약 이 시스템을 구축한다면 다음과 같은 흐름으로 작동하게 됩니다.

입력: A(쇼핑몰 컷), B(인스타 착용 샷) 입력.

전처리: 두 사진에서 '패딩' 영역만 누끼를 따듯 분리.

임베딩 (Embedding): AI 모델이 각 패딩 이미지를 고차원의 숫자 배열(벡터)로 변환. 이때 어텐션 기능이 로고나 박음질 디테일을 숫자에 반영.

유사도 측정: 두 벡터 사이의 코사인 유사도(Cosine Similarity)를 계산.

판별: 유사도가 98% 이상이면 "동일 제품", 85% 정도면 "유사 스타일", 그 이하면 "다른 제품"으로 판정.

요약
결론적으로 가능합니다. 다만, 말씀하신 것처럼 '아주 비슷한데 다른 제품(짝퉁이나 카피 제품)'을 구별하려면 데이터셋의 퀄리티가 매우 중요합니다. 미세한 박음질이나 로고 차이까지 학습된 모델(Fine-Grained Model)을 사용해야 정확도가 보장됩니다.

혹시 이 기술을 활용하려는 구체적인 서비스 형태(예: 짝퉁 탐지, 쇼핑몰 최저가 매칭 등)가 있으신가요? 그에 맞춰 더 적합한 모델이나 오픈소스 라이브러리를 추천해 드릴 수 있습니다.

쇼핑몰 최저가매칭이 내가 하고싶은 작업이야. 다만 품번으로 검색을 해도, 정확하게 딱 해당 모델이 아닌 경우에도 품번을 오기재하는 경우들이 있어서, 오묘하게 다른 제품들이 최저가로 노출이 되는데, 우리는 그 제품들을 기준으로 최저가를 잡으면 안되거든. 우리랑 같은제품에 해당하는게 뭔지를 찾아서 그거에 맞춰서 그제품보다 싸게 우리제품을 올리고싶은게 우리 니즈야

쇼핑몰 운영자 입장에서 아주 뼈아픈 포인트이자, 기술적으로 해결했을 때 마진율 방어에 직결되는 중요한 문제입니다. 품번 오기재나 키워드 어뷰징(검색에 걸리게 하려고 엉뚱한 품번을 넣는 행위) 때문에 엉뚱한 저가 상품이 매칭되면, 덩달아 가격을 내리다 손해를 보게 되니까요.

이 경우엔 단순히 '이미지가 비슷한가'만 보면 위험합니다. (디자인은 같은데 재질이 다르거나, 키즈용이거나, 연식이 다른 경우 등). 따라서 [멀티모달(Multimodal) 매칭] 전략이 필수입니다. 이미지(시각 정보)와 텍스트(제품 스펙)를 교차 검증하는 방식입니다.

구체적인 접근 방법론을 3단계 파이프라인으로 제안합니다.

1단계: 1차 필터링 (후보군 좁히기) - CLIP 모델 활용
기존의 품번 검색으로 수집된 '지저분한 후보군'들을 빠르게 정제하는 단계입니다.

기술: CLIP (Contrastive Language-Image Pre-training) 같은 멀티모달 모델을 사용합니다.

방법: '우리 제품 이미지'와 '수집된 경쟁사 이미지'들을 벡터(숫자)로 변환하여 비교합니다.

효과: * 품번은 맞게 썼는데 이미지는 엉뚱한 양말을 올려둔 경우 등을 99% 걸러냅니다.

색상이 아예 다른 제품도 여기서 1차로 걸러집니다.

핵심: 여기서 유사도가 일정 수준(예: 90%) 이상인 것만 2단계로 넘깁니다.

2단계: 세밀한 검증 (진짜 같은 제품인가?) - 속성 추출(Attribute Extraction)
이미지는 똑같은데 '기모 유무', '연식(23년형 vs 24년형)', '병행수입 여부' 등이 다른 경우를 잡아내야 합니다. 이미지만으로는 한계가 있는 부분입니다.

이미지 내 텍스트(OCR): 이미지 구석에 박혀 있는 텍스트(예: "기모 안감", "해외배송")를 OCR(광학 문자 인식) 기술로 읽어냅니다. 우리 제품엔 없는 '기모'라는 단어가 경쟁사 썸네일에 있다면 제외합니다.

텍스트 속성 비교 (NLP): 경쟁사 상품명이나 상세 페이지 텍스트에서 핵심 속성(Keyword)을 추출하여 비교합니다.

예시: 우리 제품은 '구스다운'인데, 상대방 제목에 '덕다운'이나 '웰론'이 있으면 이미지가 똑같아도 탈락(Fail) 시킵니다.

3단계: 파인 그레인드(Fine-Grained) 이미지 비교
앞서 1, 2단계를 통과했다면, 마지막으로 앞서 답변드린 딥 메트릭 러닝을 통해 옷의 디테일을 최종 확인합니다.

로고 및 패턴 정합성: 혹시 모를 '디자인 카피 제품(짝퉁)'이 섞여 있을 수 있으므로, 로고의 미세한 위치나 특정 단추 배열 등을 집중적으로 비교하여 최종 확정을 짓습니다.

시스템 구축 시나리오 (Workflow)
개발팀이나 외주를 맡기실 때, 다음과 같은 로직을 주문하시면 됩니다.

Input: 우리 제품 (이미지 A, 품번 123, 속성: 구스다운/블랙)

Scraping: 네이버 쇼핑/쿠팡 등에서 '품번 123'으로 검색된 결과 50개 수집.

AI Filtering 1 (Visual): 수집된 50개 중, 이미지 유사도가 95% 미만인 30개(다른 옷, 색상 다름 등) 자동 삭제.

AI Filtering 2 (Text/Attribute): 남은 20개 중, 제목에 '키즈', '여성용(남성용인 경우)', '베스트(패딩조끼)' 같은 제외 키워드가 있거나, OCR로 읽은 썸네일에 '스크래치 상품' 등의 문구가 있으면 삭제.

Final Match: 남은 5개가 진짜 경쟁자라고 판단.

Pricing: 그 5개 중 최저가가 10만 원이라면, 우리는 9만 9천 원으로 설정.

핵심 팁: 보수적인 접근 (False Positive 방지)
가격 책정 AI에서 가장 중요한 것은 **"놓치는 한이 있어도, 틀린 매칭은 하지 말라"**는 원칙입니다.

경쟁사를 놓치면 -> 그냥 원래 가격에 파니까 손해는 안 봅니다. (기회비용만 발생)

엉뚱한 싼 제품(짝퉁, 저퀄리티)과 매칭되면 -> 가격이 폭락하여 금전적 손실을 봅니다.

따라서, AI의 판단 신뢰도(Confidence Score)가 아주 높을 때(예: 98% 이상)만 자동 가격 조정을 하고, 90~97% 구간의 애매한 건들은 '관리자 확인 필요' 목록으로 따로 빼서 사람이 하루에 한 번 눈으로 슥 보고 승인해 주는 Human-in-the-loop 방식을 추천합니다.

이 정도 로직을 구현하려면 내부에 개발팀(특히 파이썬/머신러닝 가능한 인력)이 있으신가요, 아니면 솔루션을 찾고 계신가요? 상황에 맞춰서 오픈소스(무료) 도구를 추천해 드리거나, 상용 API를 추천해 드릴 수 있습니다.

우리는 개발자가 있고, 상품업로드를 자동화하는 프로젝트를 진행중이야. 업로드 과정에서 가격을 설정할 때 최저가를 확보하는게 우리의 전략이야. 제품은 총 5만개에 달하고, 우리가 수집할 수 있는 우리의 이미지는 1~5장 정도가 될 것 같아. 그래서 우리가 이미지를 많이 확보한게 아니라서 뭔가 learning을 시켜햐는 모델은 적합하지 않은 것 같아. 같은 제품인지여부를 판단하는 mcp 혹은 api를 외부의 것, 혹은 우리가 쉽게 개발할 수 있는 것을 만들어 낼 수 있으면 그걸 활용하면 좋을 것 같아

5만 개의 제품 스케일과 '학습 데이터(이미지) 부족'이라는 제약 조건을 고려했을 때, 별도의 모델 학습(Training) 없이 바로 사용할 수 있는 'Pre-trained Model(사전 학습된 모델)'과 'Multimodal LLM(시각 지능이 있는 거대언어모델)'의 API를 조합하는 것이 가장 효율적입니다.

개발팀이 바로 적용할 수 있는 가장 현실적이고 강력한 [Zero-shot (학습 없는) 접근법] 두 가지를 제안합니다.

방법 1. 가장 추천: "CLIP + GPT-4o(or Gemini Pro)" 하이브리드 방식
이 방식은 **"빠른 필터링"**과 **"정확한 사람 수준의 판단"**을 섞는 것입니다. 개발자가 구현하기 가장 쉽고 정확도가 높습니다.

1단계: 1차 거름망 (CLIP - 오픈소스/무료)
경쟁사 이미지를 모두 비싼 API에 넣을 순 없으니, 무료 오픈소스인 OpenAI CLIP 모델을 사용하여 벡터 유사도만 봅니다.

개발 포인트:

OpenAI의 CLIP (ViT-B/32 등) 모델을 로컬 서버나 GPU 인스턴스에 띄웁니다. (파이썬 라이브러리로 쉽게 구현 가능)

우리 제품 이미지와 크롤링한 경쟁사 이미지를 벡터로 변환(Embedding)하여 코사인 유사도를 잰 뒤, 유사도가 0.85 미만인 것들은 즉시 버립니다. (색상이 다르거나 아예 다른 옷들)

2단계: 최종 판관 (GPT-4o / Gemini 1.5 Pro - 유료 API)
살아남은 소수의 후보군(유사도 높은 이미지)에 대해, 사람이 눈으로 보듯 판단하게 합니다. 요즘 나오는 **Vision LLM(GPT-4o, Gemini 1.5 Pro 등)**은 두 이미지를 보여주고 질문을 던지면 기가 막히게 답변합니다.

개발 포인트: API에 우리 이미지와 경쟁사 이미지를 동시에 전송하고 다음과 같이 프롬프트를 보냅니다.

"이 두 개의 이미지가 완전히 동일한 제품인지 판단해. 로고의 위치, 옷깃의 형태, 단추 개수, 핏(Fit)을 비교해. 단순히 비슷해 보이는 것이 아니라, 쇼핑몰에서 동일한 품번으로 팔릴 물건인지가 중요해. 결과는 JSON 형식으로 {"is_same": boolean, "reason": "string", "confidence_score": 0-100} 만 뱉어."

장점: 학습 데이터가 하나도 없어도 됩니다. 5만 개 제품 모두 내일부터 당장 적용 가능합니다.

단점: API 비용이 듭니다. (그래서 1단계 CLIP으로 최대한 걸러내야 합니다.)

방법 2. 상용 Vision API 활용 (AWS / Google)
클라우드 인프라를 쓰고 계시다면 관리형 서비스를 쓰는 게 유지보수에 좋습니다.

Google Cloud Vision API (Product Search)
구글은 쇼핑 검색에 특화된 API 기능을 제공합니다.

Vision API Product Search: 사용자의 제품 이미지 세트(Reference Images)를 미리 등록해두고, 크롤링한 이미지를 쿼리로 날리면 가장 비슷한 제품을 찾아줍니다.

장점: '카테고리'나 '속성' 매칭에 강합니다. 인프라 관리가 필요 없습니다.

단점: 미세한 '품번 오기재'나 '짝퉁' 구별 능력은 GPT-4o 같은 생성형 AI보다 맥락 파악 능력이 조금 떨어질 수 있습니다.

개발팀을 위한 구체적인 액션 플랜 (MCP/API 관점)
저라면 **[방법 1]**을 채택하여 다음과 같이 시스템을 짤 것입니다.

이미지 벡터화 모듈 (Local/Docker):

HuggingFace의 transformers 라이브러리를 사용하여 CLIP 모델 로드.

들어오는 모든 이미지(우리 것 + 크롤링 된 것)를 512차원 벡터로 변환하여 DB(Vector DB: Milvus, Pinecone, 혹은 PGVector)에 저장.

매칭 로직 (Python Script):

벡터 거리(Distance)가 가까운 경쟁사 상품 상위 3개를 뽑음.

검증 모듈 (External API Call):

뽑힌 3개와 원본 이미지를 GPT-4o API에 전송.

프롬프트에 "이 옷의 '디테일'이 같은지 확인해. 만약 로고가 없거나 패턴이 미세하게 다르면 False를 반환해." 라고 강력한 조건을 걺.

가격 책정:

GPT가 True라고 확신(Confidence 95% 이상)한 경우에만 해당 경쟁사 가격보다 -100원 설정.

예상되는 비용과 성능
학습: 0 (Pre-trained 사용)

정확도: GPT-4o 기준, 사람은 놓치는 미세한 차이(단추 구멍 색깔 등)도 프롬프트만 잘 짜면 잡아냅니다.

속도: 1단계 필터링은 0.01초 수준, 2단계 API 검증은 1~2초 소요.

개발팀에게 **"OpenAI CLIP으로 1차 필터링하고, 헷갈리는 후보군만 GPT-4o Vision API로 검증하자"**고 제안하시면, 학습 데이터 없이 5만 개 제품을 커버하는 가장 현실적인 답이 될 것입니다.

혹시 개발팀에 전달하기 위해 **[GPT-4o에게 보낼 검증용 프롬프트 예시]**나 **[CLIP 활용 파이썬 코드 스니펫]**이 필요하시면 말씀해주세요. 작성해 드리겠습니다.

clip을 사용하는 방법 자체가 유용한지에 대해 의문이 들어. 왜냐면 어떤 이미지는 착용샷이고, 배경도 있고, 어떤 이미지는 제품만 있는 누끼샷인 경우도 있고, 누끼샷을 여러개를 포개어놓는 식으로 썸네일이미지를 만드는 경우도 있는듯 다양하거든. 어떻게 생각해?

정확하신 지적입니다. 결론부터 말씀드리면, "전처리 없이 원본 이미지를 그대로 CLIP에 넣는 방식"은 말씀하신 상황(착용샷 vs 누끼샷 vs 콜라주)에서 성능이 현저히 떨어집니다.

배경이 복잡한 '야외 착용샷'과 배경이 하얀 '누끼샷'은 CLIP 입장에서 벡터(Vector) 공간 상의 거리가 꽤 멀게 측정될 수밖에 없습니다. CLIP은 이미지의 **"주인공(패딩)"**뿐만 아니라 **"분위기(배경, 조명, 모델의 유무)"**까지 섞어서 하나의 숫자로 압축하기 때문입니다.

따라서 5만 개의 제품을 다루는 실무 환경에서는 CLIP 앞에 반드시 '전처리(Preprocessing)' 단계가 붙어야 합니다. 이 과정을 거치면 말씀하신 문제의 90% 이상을 해결할 수 있습니다.

개발팀에게 제안할 수 있는 **[현실적인 보정 파이프라인]**을 정리해 드립니다.

해결책: "찾아서(Detect) -> 자르고(Crop) -> 비교(CLIP)" 전략
이미지 전체를 비교하는 게 아니라, 이미지 속에서 우리가 비교하려는 '옷'만 강제로 끄집어내서 비교하는 방식입니다.

1단계: 객체 검출 (Object Detection) - YOLOv8 활용
가장 먼저 해야 할 일은 이미지가 '착용샷'이든 '콜라주'든 상관없이, **"패딩이 어디에 있는가?"**를 찾는 것입니다.

도구: YOLOv8 (Ultralytics) - 이미 학습된 모델을 바로 쓸 수 있고 속도가 매우 빠릅니다.

로직:

이미지를 넣으면 YOLO가 '사람(Person)' 혹은 '겉옷(Outerwear)' 영역을 네모 박스로 찾아줍니다.

착용샷: 사람 상반신 위주로 박스가 잡힙니다.

누끼샷: 옷 전체가 박스로 잡힙니다.

콜라주: 여러 개의 옷이 있으면 여러 개의 박스가 잡힙니다. (이 경우 가장 큰 박스를 선택하거나, 모든 박스를 각각 비교하면 됩니다.)

2단계: 배경 제거 및 정규화 (Background Removal) - REMBG
박스로 찾아낸 영역을 잘라낸(Crop) 뒤, 배경을 날려버립니다.

도구: rembg (파이썬 라이브러리, 무료)

효과:

야외 배경의 착용샷 -> [하얀 배경의 옷]

쇼핑몰 누끼샷 -> [하얀 배경의 옷]

결과: 이제 두 이미지는 배경 소음(Noise)이 사라지고, 오직 '옷의 형체와 색상'만 남은 상태가 되어 서로 비교 가능한 상태가 됩니다.

3단계: 이제 CLIP으로 비교
배경이 제거되고 옷만 남은 이미지끼리 CLIP에 넣어서 유사도를 측정합니다. 이렇게 하면 착용샷 vs 누끼샷이라도 "옷의 생김새"가 같다면 벡터 유사도가 훨씬 높게 나옵니다.

개발팀을 위한 구체적인 조언
개발자분에게 이렇게 전달하시면 바로 이해하실 겁니다.

"CLIP만 쓰면 배경 노이즈 때문에 정확도가 떨어질 것 같아. YOLOv8로 옷 영역을 먼저 디텍팅(Detecting)해서 크롭(Crop)하고, rembg 라이브러리로 배경을 날려서 '순수 누끼' 상태로 만든 다음에, 그 결과물을 CLIP에 넣어서 비교하는 파이프라인으로 잡아보자."

그래도 불안하다면? (하이브리드 전략)
이미지 처리가 복잡하고 리소스가 많이 든다면, 텍스트 비중을 높이는 전략도 유효합니다.

이미지보다 텍스트 우선: 이미지 유사도는 보조 지표로만 씁니다.

OCR 필터링: 이미지 내 텍스트(OCR)와 상품명 텍스트에서 '모델명', '브랜드명'이 일치하는지 먼저 봅니다.

Vision LLM (GPT-4o) 최종 검수:

CLIP 단계 없이, 그냥 원본 이미지 두 장을 GPT-4o API에 바로 던집니다.

프롬프트: "첫 번째 사진은 쇼핑몰 누끼 사진이고, 두 번째는 모델 착용 샷이야. 배경과 구도는 무시하고, 이 모델이 입고 있는 패딩이 첫 번째 사진의 패딩과 동일한 제품인지 판단해."

비용 문제: 5만 개 제품 전체를 GPT-4o로 돌리면 비용이 꽤 나옵니다. 따라서 가격 차이가 커서 이익/손실 폭이 큰 제품군이나 베스트셀러에 한해서만 GPT-4o를 쓰는 선별적 전략을 추천합니다.

요약하자면: CLIP 자체는 유용하지만 '날것'으로 쓰면 망합니다. **"YOLO(위치 찾기) + REMBG(배경 지우기)"**라는 전처리 과정을 앞에 붙여야만 원하시는 '최저가 매칭' 수준의 정확도를 확보할 수 있습니다.

제미나이 프로로 100만개의 이미지를 비교한다고 하면 얼마정도 들것같아?

Gemini 1.5 Pro 모델을 기준으로 100만 개의 이미지를 처리했을 때의 예상 비용을 계산해 드립니다. 결론부터 말씀드리면, Pro 모델은 비용이 상당히 높게 나올 수 있어 신중해야 하며, Flash 모델이 훨씬 현실적인 대안이 될 수 있습니다.

1. 비용 계산 기준 (2025년 기준 가격)
Gemini API는 이미지를 '장당' 과금하는 것이 아니라, 이미지를 **토큰(Token)**으로 환산하여 과금합니다. 이미지의 해상도에 따라 토큰 수가 달라지지만, 일반적으로 다음과 같이 계산됩니다.

기본 가정:

이미지 1장당 토큰 수: 약 258 토큰 (기본 해상도) ~ 1,290 토큰 (고해상도 1024x1024 이상, 디테일 비교용)

환율: $1 = 약 1,450원 (보수적 적용)

2. 시나리오별 예상 비용 (100만 장 기준)
A. Gemini 1.5 Pro (고성능, 디테일 정확)
옷의 재질이나 미세한 로고 차이를 보려면 Pro 모델이 확실히 좋습니다. 하지만 100만 장을 전부 Pro로 돌리기엔 부담이 큽니다.

가격: 100만(1M) 토큰당 $1.25 (약 1,812원)

저해상도 처리 시 (장당 258 토큰):

총 2.58억 토큰

비용: 약 322달러 (약 46만 원)

고해상도 처리 시 (장당 1,290 토큰 - 권장):

패딩 질감을 보려면 이 정도 토큰이 소모됩니다.

총 12.9억 토큰

비용: 약 1,612달러 (약 233만 원)

B. Gemini 1.5 Flash (가성비, 속도 빠름)
구글이 대량 처리를 위해 만든 모델입니다. 성능은 Pro보다 약간 떨어지지만 비용은 1/15 수준입니다.

가격: 100만(1M) 토큰당 $0.075 (약 108원)

저해상도 처리 시:

비용: 약 19달러 (약 2만 7천 원)

고해상도 처리 시:

비용: 약 96달러 (약 14만 원)

3. 현실적인 추천 전략
100만 장을 처리하는데 **200만 원(Pro)**을 태우는 것보다는, **14만 원(Flash)**으로 해결하는 것이 비즈니스적으로 훨씬 이득입니다.

전체 검수 (Flash 모델):

먼저 Gemini 1.5 Flash로 100만 장을 싹 돌려서 1차 매칭을 합니다. (예상 비용: 약 15만 원)

Flash 모델도 시각 지능이 뛰어나서 단순 매칭은 충분히 잘합니다.

애매한 것만 재검수 (Pro 모델):

Flash가 "확신할 수 없음(Confidence Score 낮음)"이라고 답한 상위 5~10%의 어려운 케이스만 골라내어 Gemini 1.5 Pro로 다시 확인합니다.

이렇게 하면 전체 비용을 30~40만 원 선에서 방어하면서도 정확도는 Pro 수준으로 유지할 수 있습니다.

요약: 100만 장을 그냥 Gemini 1.5 Pro로 다 돌리면 최대 230만 원 정도 나올 수 있습니다. 반면 Gemini 1.5 Flash를 쓰면 약 15만 원이면 충분합니다. Flash로 먼저 시도해 보시길 강력 추천합니다.

제미나이한테 그걸 판단하는걸 어떤식으로 시키면 될까?

Gemini에게 작업을 시킬 때 가장 중요한 것은 **"사람에게 작업 지시서를 주듯이 아주 구체적인 기준(Rubric)을 제시하는 것"**입니다. 단순히 "같은 옷이야?"라고 물으면 AI는 "비슷하니까 맞다"라고 대충 대답할 확률이 높습니다.

개발팀이 API에 바로 적용할 수 있도록, **[시스템 프롬프트(지시문)]**와 **[Python 코드 예시]**로 정리해 드립니다.

1. 강력한 프롬프트 전략 (System Prompt)
이 프롬프트는 Gemini 1.5 Flash (또는 Pro)에게 **"깐깐한 검수관"**의 페르소나를 부여합니다.

프롬프트 핵심 논리:

역할 부여: 너는 패션 이커머스 상품 검수 전문가다.

작업 정의: 기준 이미지(내 상품)와 후보 이미지(경쟁사 상품)가 **'동일한 제조사의 동일 모델(Exact Same Product)'**인지 판별해라.

예외 처리: 배경, 모델의 유무, 조명 차이, 옷이 접힌 상태는 무시해라.

콜라주 처리: 후보 이미지가 여러 옷이 섞인 썸네일(콜라주)이라면, 그 안에 내 상품과 똑같은 게 하나라도 있는지 찾아라.

출력 형식: 무조건 JSON으로 내뱉어라. (자동화를 위해 필수)

2. 실제 프롬프트 내용 (개발팀 전달용)
아래 텍스트를 API 호출 시 text 부분에 넣으면 됩니다.

Plaintext
## Role
You are a strict Fashion Product Matcher for an e-commerce price comparison engine. Your goal is to determine if "Image A" (Reference) and "Image B" (Candidate) represent the **exact same physical product**.

## Input
- Image A: Reference product (My product).
- Image B: Competitor's product image (Can be a model shot, ghost mannequin, flat lay, or a collage containing the item).

## Comparison Rules (Strict Mode)
1. **Ignore Context:** Ignore differences in background, lighting, wrinkles, or the model's face/body. Focus ONLY on the garment design.
2. **Visual Fingerprints:** Compare key design elements:
   - **Logo:** Exact match in shape, color, and placement.
   - **Hardware:** Buttons, zippers, drawstrings (color and shape).
   - **Pattern/Stitching:** Quilting patterns (horizontal vs vertical), pocket shapes, and stitch lines.
   - **Color:** Allow for slight lighting variations, but reject if it's clearly a different color variant (e.g., Black vs Navy is different).
3. **Collage Handling:** If Image B contains multiple items or a collage, check if the Reference Product (Image A) exists within Image B.
4. **Text/OCR:** If visible text (brand name, graphic print) differs, it is NOT a match.

## Output Format (JSON Only)
Return the result in the following JSON format:
{
  "is_match": boolean, // true only if you are 90%+ sure it's the exact same product.
  "confidence_score": float, // 0.0 to 1.0
  "reasoning": "string", // Briefly explain why. Mention specific matching or mismatching features.
  "candidate_type": "string" // "model_shot", "ghost_mannequin", "collage", or "unknown"
}
3. Python 코드 구현 예시 (Google Gen AI SDK)
개발자가 바로 복사해서 테스트해볼 수 있는 코드입니다.

Python
import google.generativeai as genai
from PIL import Image
import json

# 1. API 키 설정
genai.configure(api_key="YOUR_API_KEY")

# 2. 모델 설정 (가성비의 Flash 모델 권장)
model = genai.GenerativeModel('gemini-1.5-flash')

def compare_products(my_image_path, competitor_image_path):
    # 이미지 로드
    img_a = Image.open(my_image_path)
    img_b = Image.open(competitor_image_path)

    # 3. 프롬프트 구성
    prompt = """
    (위에서 작성한 영문 프롬프트 내용을 여기에 넣습니다)
    Analyze the two images provided. Image A is the first one, Image B is the second one.
    """

    # 4. API 호출 (이미지 2장 + 프롬프트 전송)
    try:
        response = model.generate_content([prompt, img_a, img_b])
        
        # JSON 파싱 (응답이 마크다운 ```json ... ``` 으로 올 경우 처리)
        result_text = response.text.replace("```json", "").replace("```", "").strip()
        result_json = json.loads(result_text)
        
        return result_json
        
    except Exception as e:
        return {"error": str(e)}

# --- 실행 예시 ---
# result = compare_products("my_padding.jpg", "competitor_thumb.jpg")
# print(result)

# 예상 출력 결과:
# {
#   "is_match": true,
#   "confidence_score": 0.95,
#   "reasoning": "Both items have the exact same triangular logo patch on the left arm and identical horizontal quilting patterns. Zipper pulls match.",
#   "candidate_type": "model_shot"
# }
4. 실무 적용 팁 (개발자를 위한 메모)
JSON Mode: Gemini 1.5 최신 버전은 response_mime_type="application/json" 옵션을 지원합니다. 이걸 쓰면 프롬프트에서 "JSON으로 줘"라고 애원하지 않아도 깔끔한 JSON이 나옵니다. 개발자에게 이 옵션을 꼭 켜라고 하세요.

Safety Settings: 가끔 모델 착용샷(특히 속옷이나 수영복이 아닌 일반 의류라도)을 '선정적'이라고 오판하여 블락하는 경우가 있습니다. API 설정에서 HARM_CATEGORY_SEXUALLY_EXPLICIT 필터를 BLOCK_NONE이나 BLOCK_ONLY_HIGH로 낮춰달라고 요청하세요.

Confidence Score 활용:

confidence_score >= 0.9: 자동 매칭 (바로 가격 조정)

0.7 <= score < 0.9: 보류 (사람이 확인하거나 가격 조정 안 함)

score < 0.7: 불일치 (무시)

이 방식으로 진행하시면, 100만 장의 이미지라도 별도의 복잡한 학습 과정 없이 Flash 모델을 통해 빠르고 저렴하게 비교 시스템을 구축하실 수 있습니다.

제미나이 api키는 어떻게 구해?

Gemini API 키는 **'Google AI Studio'**라는 개발자용 웹사이트에서 누구나 무료로 쉽게 발급받을 수 있습니다.

개발팀에게 전달하거나 직접 발급받으실 수 있도록 3단계로 정리해 드립니다.

1. 발급 절차 (30초 소요)
접속: Google AI Studio (aistudio.google.com)에 접속합니다. (구글 계정 로그인 필요)

메뉴 선택: 왼쪽 상단 메뉴에 있는 🔑 Get API key 버튼을 클릭합니다.

키 생성:

'Create API key' 버튼을 누릅니다.

**'Create API key in new project'**를 선택합니다. (기존 구글 클라우드 프로젝트가 있다면 그걸 선택해도 됩니다)

복사: AIza로 시작하는 긴 문자열이 나옵니다. 이 키를 복사해서 개발팀에게 전달하면 됩니다.

2. 요금제 확인 (중요)
쇼핑몰 대량 처리를 하시려면 'Pay-as-you-go (종량제)' 설정을 하셔야 합니다.

Free (무료 등급):

비용: 무료.

제한: 1분에 15번 요청(RPM) 제한, 하루 1,500번 제한.

용도: 개발팀이 코드를 짜고 테스트할 때 사용합니다.

Pay-as-you-go (유료 등급):

비용: 쓴 만큼 냅니다. (Flash 모델 기준 이미지 100만 장에 약 15만 원 선)

제한: 1분에 2,000~4,000번 이상 요청 가능.

용도: 실제 5만 개 상품을 업로드할 때 사용합니다.

설정 방법: API 키 페이지에서 프로젝트에 'Billing(결제 수단)'을 등록하면 자동으로 유료 등급으로 전환됩니다.

3. 개발팀 전달 메시지
개발자분에게 아래 내용을 같이 전달해주시면 바로 작업이 가능합니다.

"Google AI Studio에서 API 키 발급받았습니다. 우선 Free Tier 상태이니 코드는 이걸로 테스트해주시고, 실제 대량 매칭(배치 작업) 돌리기 전에 말씀해주시면 제가 결제 카드를 등록해서 리미트를 풀겠습니다.

키: (복사한 API 키 붙여넣기)"

지금 바로 접속해서 키를 받아보세요. 클릭 몇 번이면 됩니다.

Google 개인정보처리방침새 창에서 열기
Google 서비스 약관새 창에서 열기
개인 정보 보호 및 Gemini 앱새 창에서 열기
Gemini가 인물 등에 관한 부정확한 정보를 표시할 수 있으니 대답을 다시 한번 확인하세요.

